# ğŸŒ¾ Harvest Classification â€” CodeBasics Virtual Internship (Weeks 5 & 6)

An end-to-end **Deep Learning project** developed for the **CodeBasics Virtual Internship**, focused on **automated fruit freshness detection** using computer vision.  
The system predicts whether a fruit is **Fresh ğŸƒ** or **Spoiled ğŸ‚**, powered by multiple CNN architectures and deployed with Streamlit.

---

## ğŸ¯ Objective

To build, train, tune, and deploy a deep learning pipeline capable of classifying fruit images as *fresh* or *spoiled* across multiple fruit types.

---

## ğŸ“¦ Dataset

The dataset `FreshHarvest_Dataset` contains **8 fruit categories**, each with **Fresh (F_)** and **Spoiled (S_)** image folders:

> Banana | Lemon | Lulo | Mango | Orange | Strawberry | Tamarillo | Tomato

**Directory structure:**
```
FreshHarvest_Dataset/
 â”œâ”€â”€ F_Banana/
 â”œâ”€â”€ S_Banana/
 â”œâ”€â”€ F_Lemon/
 â”œâ”€â”€ S_Lemon/
 â”œâ”€â”€ ...
```

All images were augmented using:
- Random rotation (Â±15Â°)
- Horizontal flips
- Color jitter (brightness, contrast, saturation)
- Normalization with ImageNet statistics

---

## ğŸ§  Models Trained

Several CNN architectures were trained and compared in `dl_virtual_internship.py`.

| Model | Description | Key Features | Accuracy |
|:--|:--|:--|:--:|
| **HarvestClassifierCNN** | 3 Conv + 2 FC | Baseline CNN | ~84% |
| **CNN + Regularization** | Added BatchNorm & Dropout (0.5) | Better generalization | ~88% |
| **EfficientNet-B0** | Transfer learning | Efficient, fewer params | ~93â€“94% |
| **ResNet-50** | Fine-tuned (layer4 unfrozen) | Strong generalization | 95%+ |
| **ResNet-50 (Tuned)** | Optuna-tuned hyperparameters | Best performing model | **96%+** |

---

## âš™ï¸ Hyperparameter Tuning

Tuning was automated with **Optuna** (`hyperparameter_tunning.py`), testing 20 trials of learning-rate and dropout combinations.

| Parameter | Search Range | Best Value |
|:--|:--|:--|
| Learning Rate | 1e-5 â†’ 1e-2 | `0.0001073` |
| Dropout Rate | 0.2 â†’ 0.7 | `0.6033` |
| Optimizer | Adam | â€” |
| Epochs | 3 (for tuning) | â€” |

The best configuration was later applied to fine-tune **ResNet-50**, yielding a +1.5 % gain in validation accuracy.

---

## ğŸ“Š Model Evaluation

Final model: **ResNet-50** with Optuna-optimized hyperparameters.

| Metric | Value |
|:--|:--:|
| Training Accuracy | 98% |
| Validation Accuracy | 96% |
| Test Accuracy | 95% |
| F1-Score | 0.96 |

âœ… Excellent distinction between â€œFreshâ€ and â€œSpoiledâ€ fruits  
âœ… Minimal confusion between similar fruits (e.g., oranges vs. lemons)

The trained model weights were saved as:
```
model/saved_model.pth
```

---

## ğŸ–¼ï¸ Screenshots

Below are visuals from the Streamlit application interface .

![Training Overview](screenshots/1.png)

![App Interface](screenshots/2.png)

![Prediction Example](3.png)

---

## ğŸš€ Streamlit Deployment

A simple yet elegant **Streamlit** interface (`app.py`) enables real-time fruit classification using the trained model (`model_helper.py`).

### âœ¨ Features
- ğŸ“¤ Upload an image (`.jpg`, `.jpeg`, `.png`)
- ğŸ” Instant classification with model inference
- ğŸƒ Green for *Fresh*  
- ğŸ‚ Red for *Spoiled*
- Modern, responsive UI with Streamlit

### Run locally
```bash
pip install -r requirements.txt
streamlit run app.py
```

---

## ğŸ§© Project Structure
```
code_basics_virtual_internship_week_5_to_6/
 â”œâ”€â”€ dl_virtual_internship.py         # All model training experiments
 â”œâ”€â”€ hyperparameter_tunning.py        # Optuna-based tuning script
 â”œâ”€â”€ model_helper.py                  # ResNet architecture + inference logic
 â”œâ”€â”€ app.py                           # Streamlit app for deployment
 â”œâ”€â”€ model/
 â”‚    â””â”€â”€ saved_model.pth             # Final trained model weights
 â”œâ”€â”€ screenshots/
 â”‚    â”œâ”€â”€ training_overview.png
 â”‚    â”œâ”€â”€ app_interface.png
 â”‚    â””â”€â”€ prediction_result.png
 â”œâ”€â”€ requirements.txt                 # Dependencies list
 â””â”€â”€ README.md                        # (this file)
```

---

## ğŸ§¾ Requirements

```
streamlit==1.43.2
torch==2.7.1
torchvision==0.22.1
Pillow
numpy
matplotlib
optuna
scikit-learn
```

---

## ğŸ“ˆ Insights

- ğŸ§± Custom CNNs provided a strong baseline, but transfer learning improved performance dramatically.  
- âš™ï¸ Regularization (BatchNorm + Dropout) stabilized training.  
- ğŸ§© Optuna tuning fine-tuned ResNet hyperparameters for optimal results.  
- ğŸ“Š Augmentation played a crucial role in reducing overfitting and improving generalization.

---

## ğŸ”® Future Enhancements

- ğŸ“± Deploy to **Hugging Face Spaces** or **Streamlit Cloud**  
- ğŸ§º Extend dataset to include vegetables and multi-fruit frames  
- âš¡ Add real-time camera inference

---

## ğŸ‘¨â€ğŸ’» Author

**Somesh Joshi**  
ğŸ“ *CodeBasics Virtual Internship â€” Weeks 5 & 6*  
ğŸ”— [GitHub Profile](https://github.com/joshisomesh1996-star)

---

## ğŸªª License
Released under the **MIT License** â€” free for learning, research, and educational use.
